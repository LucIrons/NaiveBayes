{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00bead4f",
   "metadata": {},
   "source": [
    "# Building a Spam Filter with Naive Bayes\n",
    "\n",
    "## Introduction\n",
    "In this project we will build a spam filter using a multinomial Naive Bayes algorithm. This means that we will we will use data with human classifications to train the algorithm to detect spam.\n",
    "\n",
    "The data set comprises 5574 instances of spam and ham (non-spam) messages collated from multiple resources by Tiago A. Almeida and José María Gómez Hidalg and can be downloaded from [this link](https://dq-content.s3.amazonaws.com/433/SMSSpamCollection). There is more information about how the data was sourced [here](https://archive.ics.uci.edu/dataset/228/sms+spam+collection)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb981cf1",
   "metadata": {},
   "source": [
    "##  Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3636ed52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file = 'SMSSpamCollection'\n",
    "\n",
    "data = pd.read_csv(file, sep='\\t', header=None, names=['Label', 'SMS'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b12c87b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d7436f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Label   5572 non-null   object\n",
      " 1   SMS     5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d96eb536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.593683\n",
       "spam    13.406317\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportions of data set as percentages\n",
    "data['Label'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ecb438",
   "metadata": {},
   "source": [
    "## Training and Test Set\n",
    "\n",
    "It's important when building a tool like this that we retain a portion of the data to test the tool. This data should be separate from the data we train the algorithm.  So we need to split our data into:\n",
    "- a training set\n",
    "- a test set\n",
    "\n",
    "A typical ratio for this would by 80/20, since we want to train the algorithm on as much data as possible. We need the other 20% to test becuase this data has already been classified as spam or ham, meaning that we can compare the ouput from our tool against the classifications and actually measure how well the tool is working.\n",
    "\n",
    "We split the data set like this:\n",
    "- The training set will have 4,458 messages (about 80% of the dataset).\n",
    "- The test set will have 1,114 messages (about 20% of the dataset).\n",
    "\n",
    "With the tool we are aiming for an accuracy greater than 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "484e95ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n"
     ]
    }
   ],
   "source": [
    "# Randomize the dataset\n",
    "data_random = data.sample(frac=1, random_state=1)\n",
    "\n",
    "# Calculate index for split\n",
    "training_test_index = round(len(data_random) * 0.8)\n",
    "\n",
    "# Training/Test split\n",
    "training = data_random[:training_test_index].reset_index(drop=True)\n",
    "test = data_random[training_test_index:].reset_index(drop=True)\n",
    "\n",
    "print(training.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "793018b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.54105\n",
       "spam    13.45895\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportions of training set as percentages\n",
    "training['Label'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d1484d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     86.804309\n",
       "spam    13.195691\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportions of test set as percentages\n",
    "test['Label'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0ca4b0",
   "metadata": {},
   "source": [
    "We first randomized the whole data set and then split the set into to parts rows 0 to 4457 formed a new training data set and rows 4458 to 5573 became the test set. Looking at the proportions of ham and spam, we can see that they are close to that of the complete data set <0.5% difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0907023a",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "The classification that we want to make is based on the proportionality of these two equations from naives Bayes theory:\n",
    "\n",
    "$$\n",
    "  P(Spam|w_{1}, w_{2},...w_{n})\\propto P(Spam)\\cdot\\prod_{i=1}^n P(w_i|Spam)\n",
    "$$\n",
    "$$\n",
    "  P(Ham|w_{1}, w_{2},...w_{n})\\propto P(Ham)\\cdot\\prod_{i=1}^n P(w_i|Ham)\n",
    "$$\n",
    "\n",
    "In order to calculate P(w<sub>i</sub>|Spam) and P(w<sub>i</sub>|Ham), we need to use the following:\n",
    "$$\n",
    "  P(w_i|Spam) = \\frac{N_{w_{i}|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\n",
    "$$\n",
    "$$\n",
    "  P(w_i|Ham) = \\frac{N_{w_{i}|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "$$\n",
    "Where:\n",
    "$$\n",
    "N_{w_{i}|Spam} = \\text{the number of times the word }w_{i}\\text{ occurs in spam messages}\n",
    "$$\n",
    "$$\n",
    "N_{w_{i}|Ham} = \\text{the number of times the word }w_{i}\\text{ occurs in non-spam messages}\n",
    "$$\n",
    "$$\n",
    "N_{Spam} = \\text{total number of words in spam messages}\n",
    "$$\n",
    "$$\n",
    "N_{Ham} = \\text{total number of words in non-spam messages}\n",
    "$$\n",
    "$$\n",
    "N_{Vocabulary} = \\text{total number of words in vocabulary}\n",
    "$$\n",
    "$$\n",
    "\\alpha = 1 \\quad\\text{(}\\alpha\\text{ is a smoothing parameter)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c1215c",
   "metadata": {},
   "source": [
    "### Letter Case and Punctuation\n",
    "\n",
    "In order to reach this point we need to format our data differently. We can start by removing punctuation and converting everything to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa0d6b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       Yep, by the pretty sculpture\n",
       "1   ham      Yes, princess. Are you going to make me moan?\n",
       "2   ham                         Welp apparently he retired\n",
       "3   ham                                            Havent.\n",
       "4   ham  I forgot 2 ask ü all smth.. There's a card on ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d87ada1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/bggh9nlx1wx9th6t6ctvwrd00000gn/T/ipykernel_31990/1524640398.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  training['SMS'] = training['SMS'].str.replace('\\W', ' ')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       yep  by the pretty sculpture\n",
       "1   ham      yes  princess  are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training['SMS'] = training['SMS'].str.replace('\\W', ' ')\n",
    "training['SMS'] = training['SMS'].str.lower()\n",
    "\n",
    "training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7b511c",
   "metadata": {},
   "source": [
    "### Creating the Vocabulary\n",
    "\n",
    "We now need to create our vocabulary set so that we end up with something that looks like the image below:\n",
    "\n",
    "![Building a vocabulary](cpgp_dataset_3.png)\n",
    "\n",
    "We need to create a list of unique words from the SMS column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e28905a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All words: 72427\n",
      "Unique words: 7783\n"
     ]
    }
   ],
   "source": [
    "training['SMS'] = training['SMS'].str.split()\n",
    "\n",
    "vocabulary = []\n",
    "for sms in training['SMS']:\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "print(\"All words: \"+str(len(vocabulary)))        \n",
    "vocabulary = list(set(vocabulary))\n",
    "print(\"Unique words: \"+str(len(vocabulary)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "576ee55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                  [yep, by, the, pretty, sculpture]\n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...\n",
       "2   ham                    [welp, apparently, he, retired]\n",
       "3   ham                                           [havent]\n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f139770e",
   "metadata": {},
   "source": [
    "### Final Training Set\n",
    "\n",
    "We can now construct a dictionary using our vocabulary, to create a data frame that has a count of each word from the vocabulary for each sms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9531bed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word: [0] * len(training['SMS']) for unique_word in vocabulary}\n",
    "\n",
    "for index, sms in enumerate(training['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e3ce8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts_per_sms = pd.DataFrame(word_counts_per_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6323906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hearted</th>\n",
       "      <th>2day</th>\n",
       "      <th>intention</th>\n",
       "      <th>upping</th>\n",
       "      <th>pls</th>\n",
       "      <th>veggie</th>\n",
       "      <th>flood</th>\n",
       "      <th>velly</th>\n",
       "      <th>album</th>\n",
       "      <th>glasgow</th>\n",
       "      <th>...</th>\n",
       "      <th>hellogorgeous</th>\n",
       "      <th>fizz</th>\n",
       "      <th>wrld</th>\n",
       "      <th>exciting</th>\n",
       "      <th>blonde</th>\n",
       "      <th>slowly</th>\n",
       "      <th>semiobscure</th>\n",
       "      <th>tells</th>\n",
       "      <th>tones2you</th>\n",
       "      <th>vegetables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   hearted  2day  intention  upping  pls  veggie  flood  velly  album  \\\n",
       "0        0     0          0       0    0       0      0      0      0   \n",
       "1        0     0          0       0    0       0      0      0      0   \n",
       "2        0     0          0       0    0       0      0      0      0   \n",
       "3        0     0          0       0    0       0      0      0      0   \n",
       "4        0     0          0       0    0       0      0      0      0   \n",
       "\n",
       "   glasgow  ...  hellogorgeous  fizz  wrld  exciting  blonde  slowly  \\\n",
       "0        0  ...              0     0     0         0       0       0   \n",
       "1        0  ...              0     0     0         0       0       0   \n",
       "2        0  ...              0     0     0         0       0       0   \n",
       "3        0  ...              0     0     0         0       0       0   \n",
       "4        0  ...              0     0     0         0       0       0   \n",
       "\n",
       "   semiobscure  tells  tones2you  vegetables  \n",
       "0            0      0          0           0  \n",
       "1            0      0          0           0  \n",
       "2            0      0          0           0  \n",
       "3            0      0          0           0  \n",
       "4            0      0          0           0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_per_sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd395581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4458, 7783)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_per_sms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7358f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.concat([training, word_counts_per_sms], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13bd80da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>hearted</th>\n",
       "      <th>2day</th>\n",
       "      <th>intention</th>\n",
       "      <th>upping</th>\n",
       "      <th>pls</th>\n",
       "      <th>veggie</th>\n",
       "      <th>flood</th>\n",
       "      <th>velly</th>\n",
       "      <th>...</th>\n",
       "      <th>hellogorgeous</th>\n",
       "      <th>fizz</th>\n",
       "      <th>wrld</th>\n",
       "      <th>exciting</th>\n",
       "      <th>blonde</th>\n",
       "      <th>slowly</th>\n",
       "      <th>semiobscure</th>\n",
       "      <th>tells</th>\n",
       "      <th>tones2you</th>\n",
       "      <th>vegetables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  hearted  2day  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]        0     0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...        0     0   \n",
       "2   ham                    [welp, apparently, he, retired]        0     0   \n",
       "3   ham                                           [havent]        0     0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...        0     0   \n",
       "\n",
       "   intention  upping  pls  veggie  flood  velly  ...  hellogorgeous  fizz  \\\n",
       "0          0       0    0       0      0      0  ...              0     0   \n",
       "1          0       0    0       0      0      0  ...              0     0   \n",
       "2          0       0    0       0      0      0  ...              0     0   \n",
       "3          0       0    0       0      0      0  ...              0     0   \n",
       "4          0       0    0       0      0      0  ...              0     0   \n",
       "\n",
       "   wrld  exciting  blonde  slowly  semiobscure  tells  tones2you  vegetables  \n",
       "0     0         0       0       0            0      0          0           0  \n",
       "1     0         0       0       0            0      0          0           0  \n",
       "2     0         0       0       0            0      0          0           0  \n",
       "3     0         0       0       0            0      0          0           0  \n",
       "4     0         0       0       0            0      0          0           0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3334713a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4458, 7785)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f69bc08",
   "metadata": {},
   "source": [
    "## Building the Algorithm\n",
    "\n",
    "### Calculating Constants First\n",
    "\n",
    "The constants in our equations are the following:\n",
    "- $P(Ham)$ is the probability of picking ham from the classified data set: $\\frac{Number Ham Messages}{Total Messages}$\n",
    "- $P(Spam)$ is the probability of picking spam from the classified data set: $\\frac{Number Spam Messages}{Total Messages}$\n",
    "- $N_{Ham}$ is the number of words across all ham messages\n",
    "- $N_{Spam}$ is the number of words across all spam messages\n",
    "- $N_{Vocabulary}$ is the number of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bb57abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_messages = training_set[training_set['Label'] == 'ham']\n",
    "spam_messages = training_set[training_set['Label'] == 'spam']\n",
    "\n",
    "# Calculate the probabilities using the above formulas\n",
    "p_ham = len(ham_messages) / len(training_set)\n",
    "p_spam = len(spam_messages) / len(training_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "372bd3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam):  0.13458950201884254\n",
      "P(Ham):  0.8654104979811574\n",
      "n_spam:  15190\n",
      "n_ham:  57237\n",
      "n_vocab:  7783\n"
     ]
    }
   ],
   "source": [
    "# n_ham\n",
    "n_words_per_ham_message = ham_messages['SMS'].apply(len)\n",
    "n_ham = n_words_per_ham_message.sum()\n",
    "\n",
    "# n_spam\n",
    "n_words_per_spam_message = spam_messages['SMS'].apply(len)\n",
    "n_spam = n_words_per_spam_message.sum()\n",
    "\n",
    "# n_vocab\n",
    "n_vocab = len(vocabulary)\n",
    "\n",
    "# alpha\n",
    "alpha = 1\n",
    "\n",
    "print('P(Spam): ', p_spam)\n",
    "print('P(Ham): ', p_ham)\n",
    "print('n_spam: ', n_spam)\n",
    "print('n_ham: ', n_ham)\n",
    "print('n_vocab: ', n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2b3f09",
   "metadata": {},
   "source": [
    "### Calculating Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a37d4c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_word_given_ham = {unique_word: 0 for unique_word in vocabulary}\n",
    "p_word_given_spam = {unique_word: 0 for unique_word in vocabulary}\n",
    "\n",
    "for word in vocabulary:\n",
    "    # calculate for ham\n",
    "    n_word_given_ham = ham_messages[word].sum()\n",
    "    p_word_given_ham[word] = (n_word_given_ham + alpha) / (n_ham + alpha*n_vocab)  \n",
    "\n",
    "    # calculate for spam\n",
    "    n_word_given_spam = spam_messages[word].sum()\n",
    "    p_word_given_spam[word] = (n_word_given_spam + alpha) / (n_spam + alpha*n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1097824f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(himself|spam):  4.3529360553693465e-05\n",
      "P(himself|ham):  3.075976622577668e-05 \n",
      "\n",
      "P(secret|spam):  0.0003482348844295477\n",
      "P(secret|ham):  6.151953245155337e-05 \n",
      "\n",
      "P(hey|spam):  0.0006964697688590954\n",
      "P(hey|ham):  0.0016456474930790525\n"
     ]
    }
   ],
   "source": [
    "# test for the word 'himself'\n",
    "print('P(himself|spam): ', p_word_given_spam['himself'])\n",
    "print('P(himself|ham): ', p_word_given_ham['himself'],'\\n')\n",
    "\n",
    "\n",
    "# test for the word 'secret'\n",
    "print('P(secret|spam): ', p_word_given_spam['secret'])\n",
    "print('P(secret|ham): ', p_word_given_ham['secret'], '\\n')\n",
    "\n",
    "# test for the word 'hi'\n",
    "print('P(hey|spam): ', p_word_given_spam['hi'])\n",
    "print('P(hey|ham): ', p_word_given_ham['hi'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4961817f",
   "metadata": {},
   "source": [
    "##  Classifying A New Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e11b1f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "     # initialise variables for our classifying probabilities\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    for word in message:\n",
    "        if word in p_word_given_spam:\n",
    "            p_spam_given_message *= p_word_given_spam[word]\n",
    "            \n",
    "        if word in p_word_given_ham:\n",
    "            p_ham_given_message *= p_word_given_ham[word]\n",
    "\n",
    "\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "539b4d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.3481290211300841e-25\n",
      "P(Ham|message): 1.9368049028589875e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "# Test the algorithm\n",
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f9ab59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.4372375665888117e-25\n",
      "P(Ham|message): 3.687530435009238e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c31c56",
   "metadata": {},
   "source": [
    "## Measuring the Spam Filter's Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f6902173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in p_word_given_spam:\n",
    "            p_spam_given_message *= p_word_given_spam[word]\n",
    "\n",
    "        if word in p_word_given_ham:\n",
    "            p_ham_given_message *= p_word_given_ham[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d333260d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['predicted'] = test['SMS'].apply(classify_test_set)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c99dafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  98.74326750448833\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = len(test)\n",
    "\n",
    "for index,row in test.iterrows():\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct+=1\n",
    "\n",
    "    \n",
    "accuracy = correct / total\n",
    "print('accuracy: ', accuracy*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c233cef",
   "metadata": {},
   "source": [
    "We can look at some other measure if we re config this as spam an not spam - spam as a positive identification \n",
    "- TP = correctly labelled spam\n",
    "- FP = incorrectly labelled spam\n",
    "- TN = correctly labelled non-spam\n",
    "- FN = incorrectly labelled non-spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2488acc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 98.74%\n",
      "\n",
      "“Out of all the positive predictions we made, how many were true?”\n",
      "precision: 96.53% \n",
      "\n",
      "“Out of all the data points that should be predicted as true, how many did we correctly predict as true?”\n",
      "recall: 94.56%\n",
      "\n",
      "f1: 95.53%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tp=0\n",
    "fp=0\n",
    "tn=0\n",
    "fn=0\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    if (row['Label'] == 'spam') & (row['predicted'] == 'spam'):\n",
    "        tp+=1\n",
    "    if (row['Label'] == 'ham') & (row['predicted'] == 'spam'):\n",
    "        fp+=1\n",
    "    if (row['Label'] == 'ham') & (row['predicted'] == 'ham'):\n",
    "        tn+=1\n",
    "    if (row['Label'] == 'spam') & (row['predicted'] == 'ham'):\n",
    "        fn+=1\n",
    "        \n",
    "accuracy = (tp+tn) / total\n",
    "precision = tp / (tp+fp)\n",
    "recall = tp / (tp+fn)\n",
    "f1 = 2*(precision*recall) / (precision+recall)\n",
    "\n",
    "print('accuracy: {:.2%}\\n'.format(accuracy))\n",
    "print('“Out of all the positive predictions we made, how many were true?”')\n",
    "print('precision: {:.2%} \\n'.format(precision))\n",
    "print('“Out of all the data points that should be predicted as true, how many did we correctly predict as true?”')\n",
    "print('recall: {:.2%}\\n'.format(recall))\n",
    "print('We combine recall and precision in an f1 sco')\n",
    "print('f1: {:.2%}\\n'.format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea8ea86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
